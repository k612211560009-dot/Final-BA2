{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42644436",
   "metadata": {},
   "source": [
    "## I. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install lightgbm shap scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load compressor features\n",
    "DATA_DIR = Path('../data/features')\n",
    "FEATURES_FILE = DATA_DIR / 'compressor_features.csv'\n",
    "\n",
    "print(f\"Loading data from: {FEATURES_FILE}\")\n",
    "df = pd.read_csv(FEATURES_FILE)\n",
    "\n",
    "# Convert timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"\\n‚úì Data loaded successfully\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"  Compressors: {df['equipment_id'].unique()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534488d5",
   "metadata": {},
   "source": [
    "## II. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c70ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"=\"*70)\n",
    "print(\"COMPRESSOR DATASET OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal records: {len(df):,}\")\n",
    "print(f\"Unique compressors: {df['equipment_id'].nunique()}\")\n",
    "print(f\"Features: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No missing values\")\n",
    "\n",
    "print(f\"\\nKey statistics:\")\n",
    "print(f\"  Mean health index: {df['health_index'].mean():.3f}\")\n",
    "print(f\"  Mean efficiency: {df['efficiency_normalized'].mean():.3f}\")\n",
    "print(f\"  Mean RUL: {df['rul_days'].mean():.1f} days\")\n",
    "print(f\"  Anomaly rate: {df['is_anomaly'].sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-compressor statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-COMPRESSOR STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for comp_id in df['equipment_id'].unique():\n",
    "    comp_df = df[df['equipment_id'] == comp_id]\n",
    "    print(f\"\\n{comp_id}:\")\n",
    "    print(f\"  Records: {len(comp_df):,}\")\n",
    "    print(f\"  Health: {comp_df['health_index'].mean():.3f}\")\n",
    "    print(f\"  Efficiency: {comp_df['efficiency_normalized'].mean():.3f}\")\n",
    "    print(f\"  RUL: {comp_df['rul_days'].mean():.1f} days\")\n",
    "    print(f\"  Anomalies: {comp_df['is_anomaly'].sum()} ({comp_df['is_anomaly'].sum()/len(comp_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac81d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Health index distribution\n",
    "axes[0, 0].hist(df['health_index'], bins=50, edgecolor='black')\n",
    "axes[0, 0].set_title('Health Index Distribution')\n",
    "axes[0, 0].set_xlabel('Health Index')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Efficiency distribution\n",
    "axes[0, 1].hist(df['efficiency_normalized'], bins=50, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('Efficiency Distribution')\n",
    "axes[0, 1].set_xlabel('Efficiency (normalized)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# RUL distribution\n",
    "axes[0, 2].hist(df['rul_days'], bins=50, edgecolor='black', color='green')\n",
    "axes[0, 2].set_title('RUL Distribution')\n",
    "axes[0, 2].set_xlabel('RUL (days)')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Health trend over time (sample)\n",
    "sample_df = df[df['equipment_id'] == 'COMP_001'].head(5000)\n",
    "axes[1, 0].plot(sample_df['timestamp'], sample_df['health_index'])\n",
    "axes[1, 0].set_title('Health Index Trend (COMP_001 sample)')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Health Index')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Efficiency vs Health\n",
    "axes[1, 1].scatter(df['efficiency_normalized'], df['health_index'], alpha=0.1)\n",
    "axes[1, 1].set_title('Efficiency vs Health Index')\n",
    "axes[1, 1].set_xlabel('Efficiency (normalized)')\n",
    "axes[1, 1].set_ylabel('Health Index')\n",
    "\n",
    "# Anomaly rate by compressor\n",
    "anomaly_rate = df.groupby('equipment_id')['is_anomaly'].mean() * 100\n",
    "axes[1, 2].bar(anomaly_rate.index, anomaly_rate.values, color=['red', 'orange', 'yellow'])\n",
    "axes[1, 2].set_title('Anomaly Rate by Compressor')\n",
    "axes[1, 2].set_xlabel('Compressor')\n",
    "axes[1, 2].set_ylabel('Anomaly Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/eda_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì EDA plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdaea73",
   "metadata": {},
   "source": [
    "## III. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "# Exclude identifiers, timestamps, and target variables\n",
    "exclude_cols = [\n",
    "    'equipment_id', 'timestamp', 'location', 'manufacturer', 'model',\n",
    "    'health_index', 'rul_days', 'is_anomaly', 'efficiency_normalized'\n",
    "]\n",
    "\n",
    "# Operational features\n",
    "operational_features = [\n",
    "    'motor_speed_rpm', 'flow_rate_m3h', 'discharge_pressure_bar',\n",
    "    'suction_pressure_bar', 'motor_power_kw', 'temperature_c',\n",
    "    'pressure_ratio', 'specific_power', 'efficiency_proxy', 'load_factor'\n",
    "]\n",
    "\n",
    "# Vibration features\n",
    "vibration_features = [\n",
    "    'vibration_rms_mms', 'vibration_peak_mms', 'vibration_severity',\n",
    "    'bearing_health_indicator', 'vibration_trend_slope'\n",
    "]\n",
    "\n",
    "# Rolling statistics\n",
    "rolling_features = [\n",
    "    'motor_speed_rolling_mean', 'motor_speed_rolling_std',\n",
    "    'temperature_rolling_mean', 'temperature_rolling_std',\n",
    "    'vibration_rms_rolling_mean', 'vibration_rms_rolling_std',\n",
    "    'efficiency_rolling_mean', 'efficiency_rolling_std'\n",
    "]\n",
    "\n",
    "# Condition scores\n",
    "condition_features = ['bearing_condition_score', 'seal_condition_score']\n",
    "\n",
    "# All features for modeling\n",
    "all_features = operational_features + vibration_features + rolling_features + condition_features\n",
    "\n",
    "print(f\"Total features for modeling: {len(all_features)}\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"  Operational: {len(operational_features)}\")\n",
    "print(f\"  Vibration: {len(vibration_features)}\")\n",
    "print(f\"  Rolling stats: {len(rolling_features)}\")\n",
    "print(f\"  Condition scores: {len(condition_features)}\")\n",
    "\n",
    "# Check for missing features\n",
    "missing_features = [f for f in all_features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n‚ö† Warning: Missing features: {missing_features}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì All features present in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d09618",
   "metadata": {},
   "source": [
    "## IV. Model 1 - Efficiency Degradation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe19e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for efficiency prediction\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: EFFICIENCY DEGRADATION PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Remove rows with NaN in rolling features (first few rows)\n",
    "df_clean = df.dropna(subset=all_features + ['efficiency_normalized'])\n",
    "\n",
    "X_eff = df_clean[all_features]\n",
    "y_eff = df_clean['efficiency_normalized']\n",
    "\n",
    "# Train/test split (80/20, stratified by compressor)\n",
    "X_train_eff, X_test_eff, y_train_eff, y_test_eff = train_test_split(\n",
    "    X_eff, y_eff, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_eff):,} samples\")\n",
    "print(f\"  Test: {len(X_test_eff):,} samples\")\n",
    "print(f\"  Features: {X_train_eff.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM regressor for efficiency\n",
    "params_eff = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"\\nTraining LightGBM model...\")\n",
    "train_data_eff = lgb.Dataset(X_train_eff, label=y_train_eff)\n",
    "test_data_eff = lgb.Dataset(X_test_eff, label=y_test_eff, reference=train_data_eff)\n",
    "\n",
    "model_eff = lgb.train(\n",
    "    params_eff,\n",
    "    train_data_eff,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[train_data_eff, test_data_eff],\n",
    "    valid_names=['train', 'test'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate efficiency model\n",
    "y_pred_eff_train = model_eff.predict(X_train_eff, num_iteration=model_eff.best_iteration)\n",
    "y_pred_eff_test = model_eff.predict(X_test_eff, num_iteration=model_eff.best_iteration)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse_eff = np.sqrt(mean_squared_error(y_train_eff, y_pred_eff_train))\n",
    "test_rmse_eff = np.sqrt(mean_squared_error(y_test_eff, y_pred_eff_test))\n",
    "train_mae_eff = mean_absolute_error(y_train_eff, y_pred_eff_train)\n",
    "test_mae_eff = mean_absolute_error(y_test_eff, y_pred_eff_test)\n",
    "train_r2_eff = r2_score(y_train_eff, y_pred_eff_train)\n",
    "test_r2_eff = r2_score(y_test_eff, y_pred_eff_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EFFICIENCY MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  RMSE: {train_rmse_eff:.4f}\")\n",
    "print(f\"  MAE:  {train_mae_eff:.4f}\")\n",
    "print(f\"  R¬≤:   {train_r2_eff:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse_eff:.4f}\")\n",
    "print(f\"  MAE:  {test_mae_eff:.4f}\")\n",
    "print(f\"  R¬≤:   {test_r2_eff:.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_eff = {\n",
    "    'model': 'Efficiency Degradation',\n",
    "    'train_rmse': float(train_rmse_eff),\n",
    "    'test_rmse': float(test_rmse_eff),\n",
    "    'train_mae': float(train_mae_eff),\n",
    "    'test_mae': float(test_mae_eff),\n",
    "    'train_r2': float(train_r2_eff),\n",
    "    'test_r2': float(test_r2_eff)\n",
    "}\n",
    "\n",
    "import json\n",
    "Path('../models/compressor_evaluation').mkdir(parents=True, exist_ok=True)\n",
    "with open('../models/compressor_evaluation/metrics_efficiency.json', 'w') as f:\n",
    "    json.dump(metrics_eff, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Metrics saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf71c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted (efficiency)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Test set\n",
    "axes[0].scatter(y_test_eff, y_pred_eff_test, alpha=0.3)\n",
    "axes[0].plot([y_test_eff.min(), y_test_eff.max()], \n",
    "             [y_test_eff.min(), y_test_eff.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Efficiency')\n",
    "axes[0].set_ylabel('Predicted Efficiency')\n",
    "axes[0].set_title(f'Efficiency Model - Test Set\\nR¬≤ = {test_r2_eff:.3f}, RMSE = {test_rmse_eff:.4f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals_eff = y_test_eff - y_pred_eff_test\n",
    "axes[1].scatter(y_pred_eff_test, residuals_eff, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Efficiency')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/efficiency_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Prediction plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a5d48",
   "metadata": {},
   "source": [
    "## V. Model 2 - RUL Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8045460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for RUL prediction\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: RUL PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_rul = df_clean[all_features]\n",
    "y_rul = df_clean['rul_days']\n",
    "\n",
    "# Train/test split\n",
    "X_train_rul, X_test_rul, y_train_rul, y_test_rul = train_test_split(\n",
    "    X_rul, y_rul, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_rul):,} samples\")\n",
    "print(f\"  Test: {len(X_test_rul):,} samples\")\n",
    "print(f\"  RUL range: {y_rul.min():.0f} - {y_rul.max():.0f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM regressor for RUL\n",
    "params_rul = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"\\nTraining LightGBM model for RUL...\")\n",
    "train_data_rul = lgb.Dataset(X_train_rul, label=y_train_rul)\n",
    "test_data_rul = lgb.Dataset(X_test_rul, label=y_test_rul, reference=train_data_rul)\n",
    "\n",
    "model_rul = lgb.train(\n",
    "    params_rul,\n",
    "    train_data_rul,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[train_data_rul, test_data_rul],\n",
    "    valid_names=['train', 'test'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì RUL model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7139d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RUL model\n",
    "y_pred_rul_train = model_rul.predict(X_train_rul, num_iteration=model_rul.best_iteration)\n",
    "y_pred_rul_test = model_rul.predict(X_test_rul, num_iteration=model_rul.best_iteration)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse_rul = np.sqrt(mean_squared_error(y_train_rul, y_pred_rul_train))\n",
    "test_rmse_rul = np.sqrt(mean_squared_error(y_test_rul, y_pred_rul_test))\n",
    "train_mae_rul = mean_absolute_error(y_train_rul, y_pred_rul_train)\n",
    "test_mae_rul = mean_absolute_error(y_test_rul, y_pred_rul_test)\n",
    "train_r2_rul = r2_score(y_train_rul, y_pred_rul_train)\n",
    "test_r2_rul = r2_score(y_test_rul, y_pred_rul_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUL MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  RMSE: {train_rmse_rul:.1f} days\")\n",
    "print(f\"  MAE:  {train_mae_rul:.1f} days\")\n",
    "print(f\"  R¬≤:   {train_r2_rul:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse_rul:.1f} days\")\n",
    "print(f\"  MAE:  {test_mae_rul:.1f} days\")\n",
    "print(f\"  R¬≤:   {test_r2_rul:.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_rul = {\n",
    "    'model': 'RUL Prediction',\n",
    "    'train_rmse': float(train_rmse_rul),\n",
    "    'test_rmse': float(test_rmse_rul),\n",
    "    'train_mae': float(train_mae_rul),\n",
    "    'test_mae': float(test_mae_rul),\n",
    "    'train_r2': float(train_r2_rul),\n",
    "    'test_r2': float(test_r2_rul)\n",
    "}\n",
    "\n",
    "with open('../models/compressor_evaluation/metrics_rul.json', 'w') as f:\n",
    "    json.dump(metrics_rul, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Metrics saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043bcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RUL predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test_rul, y_pred_rul_test, alpha=0.3)\n",
    "axes[0].plot([y_test_rul.min(), y_test_rul.max()], \n",
    "             [y_test_rul.min(), y_test_rul.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual RUL (days)')\n",
    "axes[0].set_ylabel('Predicted RUL (days)')\n",
    "axes[0].set_title(f'RUL Model - Test Set\\nR¬≤ = {test_r2_rul:.3f}, RMSE = {test_rmse_rul:.1f} days')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals_rul = y_test_rul - y_pred_rul_test\n",
    "axes[1].scatter(y_pred_rul_test, residuals_rul, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted RUL (days)')\n",
    "axes[1].set_ylabel('Residuals (days)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/rul_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì RUL prediction plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0972c5",
   "metadata": {},
   "source": [
    "## VI. Model 3 - Anomaly Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for anomaly classification\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: ANOMALY CLASSIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_anom = df_clean[all_features]\n",
    "y_anom = df_clean['is_anomaly'].astype(int)\n",
    "\n",
    "# Train/test split\n",
    "X_train_anom, X_test_anom, y_train_anom, y_test_anom = train_test_split(\n",
    "    X_anom, y_anom, test_size=0.2, random_state=42, stratify=y_anom\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_anom):,} samples\")\n",
    "print(f\"  Test: {len(X_test_anom):,} samples\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(f\"  Normal: {(y_train_anom == 0).sum():,} ({(y_train_anom == 0).sum()/len(y_train_anom)*100:.1f}%)\")\n",
    "print(f\"  Anomaly: {(y_train_anom == 1).sum():,} ({(y_train_anom == 1).sum()/len(y_train_anom)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM classifier for anomalies\n",
    "params_anom = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'is_unbalance': True,  # Handle class imbalance\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"\\nTraining LightGBM classifier...\")\n",
    "train_data_anom = lgb.Dataset(X_train_anom, label=y_train_anom)\n",
    "test_data_anom = lgb.Dataset(X_test_anom, label=y_test_anom, reference=train_data_anom)\n",
    "\n",
    "model_anom = lgb.train(\n",
    "    params_anom,\n",
    "    train_data_anom,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[train_data_anom, test_data_anom],\n",
    "    valid_names=['train', 'test'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Anomaly model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate anomaly model\n",
    "y_pred_anom_prob_test = model_anom.predict(X_test_anom, num_iteration=model_anom.best_iteration)\n",
    "y_pred_anom_test = (y_pred_anom_prob_test > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(y_test_anom, y_pred_anom_test)\n",
    "prec = precision_score(y_test_anom, y_pred_anom_test)\n",
    "rec = recall_score(y_test_anom, y_pred_anom_test)\n",
    "f1 = f1_score(y_test_anom, y_pred_anom_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANOMALY MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Accuracy:  {acc:.4f}\")\n",
    "print(f\"  Precision: {prec:.4f}\")\n",
    "print(f\"  Recall:    {rec:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_anom, y_pred_anom_test, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_anom, y_pred_anom_test)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"Actual    Normal  Anomaly\")\n",
    "print(f\"Normal    {cm[0,0]:6d}  {cm[0,1]:6d}\")\n",
    "print(f\"Anomaly   {cm[1,0]:6d}  {cm[1,1]:6d}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_anom = {\n",
    "    'model': 'Anomaly Classification',\n",
    "    'accuracy': float(acc),\n",
    "    'precision': float(prec),\n",
    "    'recall': float(rec),\n",
    "    'f1_score': float(f1)\n",
    "}\n",
    "\n",
    "with open('../models/compressor_evaluation/metrics_anomaly.json', 'w') as f:\n",
    "    json.dump(metrics_anom, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Metrics saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645641a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title(f'Confusion Matrix - Anomaly Classification\\nAccuracy: {acc:.3f}, F1: {f1:.3f}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aba724",
   "metadata": {},
   "source": [
    "## VII. SHAP Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4766ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for efficiency model\n",
    "print(\"Calculating SHAP values for Efficiency model...\")\n",
    "explainer_eff = shap.TreeExplainer(model_eff)\n",
    "shap_values_eff = explainer_eff.shap_values(X_test_eff.head(1000))  # Sample for speed\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_eff, X_test_eff.head(1000), show=False)\n",
    "plt.title('SHAP Feature Importance - Efficiency Model', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/shap_efficiency.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì SHAP analysis complete for Efficiency model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for RUL model\n",
    "print(\"Calculating SHAP values for RUL model...\")\n",
    "explainer_rul = shap.TreeExplainer(model_rul)\n",
    "shap_values_rul = explainer_rul.shap_values(X_test_rul.head(1000))\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_rul, X_test_rul.head(1000), show=False)\n",
    "plt.title('SHAP Feature Importance - RUL Model', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/shap_rul.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì SHAP analysis complete for RUL model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a550db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Efficiency model\n",
    "importance_eff = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': model_eff.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[0].barh(range(len(importance_eff)), importance_eff['importance'])\n",
    "axes[0].set_yticks(range(len(importance_eff)))\n",
    "axes[0].set_yticklabels(importance_eff['feature'])\n",
    "axes[0].set_xlabel('Importance (Gain)')\n",
    "axes[0].set_title('Top 15 Features - Efficiency Model')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# RUL model\n",
    "importance_rul = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': model_rul.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[1].barh(range(len(importance_rul)), importance_rul['importance'])\n",
    "axes[1].set_yticks(range(len(importance_rul)))\n",
    "axes[1].set_yticklabels(importance_rul['feature'])\n",
    "axes[1].set_xlabel('Importance (Gain)')\n",
    "axes[1].set_title('Top 15 Features - RUL Model')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/compressor_evaluation/feature_importance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Feature importance comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f86e71",
   "metadata": {},
   "source": [
    "## VIII. Predictions & Maintenance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all compressors\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING PREDICTIONS FOR MAINTENANCE SCHEDULING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get latest data point per compressor\n",
    "latest_data = df_clean.groupby('equipment_id').last().reset_index()\n",
    "\n",
    "X_latest = latest_data[all_features]\n",
    "\n",
    "# Predictions\n",
    "pred_efficiency = model_eff.predict(X_latest, num_iteration=model_eff.best_iteration)\n",
    "pred_rul = model_rul.predict(X_latest, num_iteration=model_rul.best_iteration)\n",
    "pred_anomaly_prob = model_anom.predict(X_latest, num_iteration=model_anom.best_iteration)\n",
    "pred_anomaly = (pred_anomaly_prob > 0.5).astype(int)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'equipment_id': latest_data['equipment_id'],\n",
    "    'current_efficiency': latest_data['efficiency_normalized'].values,\n",
    "    'predicted_efficiency': pred_efficiency,\n",
    "    'efficiency_change': pred_efficiency - latest_data['efficiency_normalized'].values,\n",
    "    'current_rul_days': latest_data['rul_days'].values,\n",
    "    'predicted_rul_days': pred_rul,\n",
    "    'rul_change': pred_rul - latest_data['rul_days'].values,\n",
    "    'anomaly_probability': pred_anomaly_prob,\n",
    "    'is_anomaly_predicted': pred_anomaly,\n",
    "    'current_health': latest_data['health_index'].values\n",
    "})\n",
    "\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Save predictions\n",
    "summary.to_csv('../models/compressor_evaluation/predictions_summary.csv', index=False)\n",
    "print(\"\\n‚úì Predictions saved to CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be19153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenance priority ranking\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MAINTENANCE PRIORITY RANKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate priority score (lower = more urgent)\n",
    "summary['priority_score'] = (\n",
    "    summary['predicted_rul_days'] * 0.40 +  # Lower RUL = higher priority\n",
    "    (1 - summary['predicted_efficiency']) * 1000 * 0.30 +  # Lower efficiency = higher priority\n",
    "    summary['anomaly_probability'] * 500 * 0.30  # Higher anomaly prob = higher priority\n",
    ")\n",
    "\n",
    "summary_sorted = summary.sort_values('priority_score')\n",
    "\n",
    "# Assign priority levels\n",
    "def assign_priority(row):\n",
    "    if row['predicted_rul_days'] < 365 or row['anomaly_probability'] > 0.8:\n",
    "        return 'P1 - Immediate'\n",
    "    elif row['predicted_rul_days'] < 730 or row['predicted_efficiency'] < 0.3:\n",
    "        return 'P2 - Urgent'\n",
    "    elif row['predicted_rul_days'] < 1825:\n",
    "        return 'P3 - Scheduled'\n",
    "    else:\n",
    "        return 'P4 - Normal'\n",
    "\n",
    "summary_sorted['priority_level'] = summary_sorted.apply(assign_priority, axis=1)\n",
    "\n",
    "print(\"\\nMaintenance Schedule (by priority):\")\n",
    "print(summary_sorted[[\n",
    "    'equipment_id', 'priority_level', 'predicted_rul_days', \n",
    "    'predicted_efficiency', 'anomaly_probability'\n",
    "]].to_string(index=False))\n",
    "\n",
    "# Save maintenance schedule\n",
    "summary_sorted.to_csv('../models/compressor_evaluation/maintenance_schedule.csv', index=False)\n",
    "print(\"\\n‚úì Maintenance schedule saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa008b42",
   "metadata": {},
   "source": [
    "## IX. Model Export & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce858146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "print(\"=\"*70)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_eff.save_model('../models/compressor_efficiency_model.txt')\n",
    "print(\"‚úì Efficiency model saved: compressor_efficiency_model.txt\")\n",
    "\n",
    "model_rul.save_model('../models/compressor_rul_model.txt')\n",
    "print(\"‚úì RUL model saved: compressor_rul_model.txt\")\n",
    "\n",
    "model_anom.save_model('../models/compressor_anomaly_model.txt')\n",
    "print(\"‚úì Anomaly model saved: compressor_anomaly_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df13f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPRESSOR MODELING - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(f\"  Total records: {len(df):,}\")\n",
    "print(f\"  Compressors: {df['equipment_id'].nunique()}\")\n",
    "print(f\"  Features: {len(all_features)}\")\n",
    "\n",
    "print(\"\\nüéØ Model 1 - Efficiency Degradation:\")\n",
    "print(f\"  Test RMSE: {test_rmse_eff:.4f}\")\n",
    "print(f\"  Test R¬≤: {test_r2_eff:.4f}\")\n",
    "print(f\"  Top feature: {importance_eff.iloc[0]['feature']}\")\n",
    "\n",
    "print(\"\\nüéØ Model 2 - RUL Prediction:\")\n",
    "print(f\"  Test RMSE: {test_rmse_rul:.1f} days\")\n",
    "print(f\"  Test R¬≤: {test_r2_rul:.4f}\")\n",
    "print(f\"  Top feature: {importance_rul.iloc[0]['feature']}\")\n",
    "\n",
    "print(\"\\nüéØ Model 3 - Anomaly Classification:\")\n",
    "print(f\"  Accuracy: {acc:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {prec:.4f}\")\n",
    "print(f\"  Recall: {rec:.4f}\")\n",
    "\n",
    "print(\"\\nüîß Maintenance Recommendations:\")\n",
    "for priority in ['P1 - Immediate', 'P2 - Urgent', 'P3 - Scheduled', 'P4 - Normal']:\n",
    "    count = (summary_sorted['priority_level'] == priority).sum()\n",
    "    if count > 0:\n",
    "        equipment = summary_sorted[summary_sorted['priority_level'] == priority]['equipment_id'].tolist()\n",
    "        print(f\"  {priority}: {count} compressor(s) - {', '.join(equipment)}\")\n",
    "\n",
    "print(\"\\nüìÅ Saved Files:\")\n",
    "print(\"  Models:\")\n",
    "print(\"    - compressor_efficiency_model.txt\")\n",
    "print(\"    - compressor_rul_model.txt\")\n",
    "print(\"    - compressor_anomaly_model.txt\")\n",
    "print(\"\\n  Evaluation:\")\n",
    "print(\"    - metrics_efficiency.json\")\n",
    "print(\"    - metrics_rul.json\")\n",
    "print(\"    - metrics_anomaly.json\")\n",
    "print(\"    - efficiency_predictions.png\")\n",
    "print(\"    - rul_predictions.png\")\n",
    "print(\"    - confusion_matrix.png\")\n",
    "print(\"    - shap_efficiency.png\")\n",
    "print(\"    - shap_rul.png\")\n",
    "print(\"    - feature_importance_comparison.png\")\n",
    "print(\"\\n  Predictions:\")\n",
    "print(\"    - predictions_summary.csv\")\n",
    "print(\"    - maintenance_schedule.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì COMPRESSOR MODELING COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
